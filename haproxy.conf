#
# dvv's way to configure haproxy
#

global

	maxconn 32768 # concurrent connections limit
	log 127.0.0.1 local0
	#chroot /usr/share/haproxy
	user haproxy
	group haproxy
	#daemon
	# distribute the health checks with a bit of randomness
	spread-checks 5
	#debug
	#quiet

defaults

	log global
	mode http
	option abortonclose
	no option accept-invalid-http-request
	no option accept-invalid-http-response
	option allbackups
	#option dontlognull
	option forwardfor except 127.0.0.1 header X-Forwarded-For
	option httpchk GET /haproxy?monitor
	http-check disable-on-404
	option httplog
	option log-separate-errors
	option redispatch
	retries 3
	#?option splice-auto
	option tcp-smart-connect

frontend test-ws-cluster

	# uncomment to disable temporarily
	#disabled

	maxconn 4096

	#
	# listen to vanilla HTTP
	#
	# CONFIG: edit address:port for HTTP
	#
	bind 0.0.0.0:3000
	#
	#
	#

	#
	# listen to HTTPS thru Stunnel
	#
	# CONFIG: edit port for HTTPS internal port.
	# the same value should be used in stunnel.conf
	#
	bind 127.0.0.1:8000 accept-proxy
	#
	#
	#

	# block bad guys
	# N.B. should be tuned in production
	reqitarpit . if ! LOCALHOST

	# monitor
	monitor-uri /haproxy?alive
	acl site_dead nbsrv(dynamic) lt 2
	acl site_dead nbsrv(static)  lt 2
	monitor fail if site_dead

	# proxy HTTP
	default_backend http
	# proxy true WebSockets and socket.io fallbacks
	acl is_websocket hdr(upgrade) -i websocket
	acl is_websocket hdr_beg(host) -i ws
	# N.B. the best is to place socket.io.min.js under production static server
	# so that it won't interfere here
	acl is_websocket path_beg /socket.io/
	use_backend websockets if is_websocket
	# TODO: consider tuning: honor socketio cookie and route to specific backends
	# ???

	#
	# TODO: how to vary depending on backend?
	#
	# client must send the data within 25 seconds. should equal server timeout
	# TODO: long upload? route to another server?
	timeout client 1d #25s

backend http

	# workers
	fullconn 10000
	default-server weight 50 maxqueue 16384 minconn 512 maxconn 16384 slowstart 1000 inter 5000 fastinter 500 downinter 10000 rise 2 fall 3

	#
	# CONFIG: enlist workers
	#
	server s1 127.0.0.1:3001 check cookie s1
	server s2 127.0.0.1:3002 check cookie s2
	server s3 127.0.0.1:3003 check cookie s3
	server s4 127.0.0.1:3004 check backup

	# balance the load
	balance leastconn

	# cookie persistence
	cookie SERVERID insert indirect postonly

	# health check
	#http-check expect string foo1

	# admin interface
	stats enable
	stats uri /haproxy?stats
	stats hide-version
	#stats refresh 3s
	stats admin if LOCALHOST

	# timeouts
	option forceclose
	# server must be contacted within 5 seconds
	timeout connect 5s
	# all headers must arrive within 3 seconds
	timeout http-request 3s
	# server must respond within 25 seconds. should equal client timeout
	timeout server 25s
	#
	# don't close connection for 1 ms
	# helps to glue several short requests in one session
	# N.B. >10 can dramatically slow down short requests
	#
	timeout http-keep-alive 1

backend websockets

	# workers
	default-server weight 50 maxqueue 16384 maxconn 16384 slowstart 1000 inter 5000 fastinter 500 downinter 10000 rise 2 fall 3
	#
	# CONFIG: enlist workers.
	# you should copy the list from above section
	#
	server s1 127.0.0.1:3001 check cookie s1
	server s2 127.0.0.1:3002 check cookie s2
	server s3 127.0.0.1:3003 check cookie s3
	server s4 127.0.0.1:3004 check backup

	# balance the load
	balance roundrobin

	# cookie persistence
	cookie SERVERID insert indirect nocache

	# adjust session rate
	#rate-limit sessions 10

	# timeouts
	#option forceclose
	timeout queue 5s
	# support long-polling: socket.io uses circa 20-25 second requests, lets double the time
	timeout connect 60s
	timeout server 60s
